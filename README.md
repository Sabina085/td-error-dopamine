# td-error-dopamine
A Python implementation for simulating some of the TD learning experiments from the paper "A neural substrate of prediction and reward"  (Schultz, W., Dayan, P., Montague, R.P)

The code is based on the MATLAB implementation from https://github.com/sjgershm/RL-tutorial.

<hr>

<p> Before learning </p>
<p>
  <img src="Results/before_learning.png" width="300" height="200" />
</p>
<hr>
<p> After learning </p>
<p float="left">
  <img src="Results/after_learning_5.png" width="300" height="200" />
  <img src="Results/after_learning_20.png" width="300" height="200" />
 </p>
<p float="left">
  <img src="Results/after_learning_50.png" width="300" height="200" />
  <img src="Results/after_learning_100.png" width="300" height="200" />
</p>

<hr>
<p> Reward omission </p>
<p float="left">
  <img src="Results/reward_omission_5.png" width="300" height="200" />
  <img src="Results/reward_omission_20.png" width="300" height="200" />
 </p>
<p float="left">
  <img src="Results/reward_omission_50.png" width="300" height="200" />
  <img src="Results/reward_omission_100.png" width="300" height="200" />
</p>

<hr>
<p> Delayed reward </p>
<p float="left">
  <img src="Results/delayed_reward_5.png" width="300" height="200" />
  <img src="Results/delayed_reward_20.png" width="300" height="200" />
 </p>
<p float="left">
  <img src="Results/delayed_reward_50.png" width="300" height="200" />
  <img src="Results/delayed_reward_100.png" width="300" height="200" />
</p>

<hr>

<p> Early reward </p>

<p float="left">
  <img src="Results/early_reward_5.png" width="300" height="200" />
  <img src="Results/early_reward_20.png" width="300" height="200" />
 </p>
<p float="left">
  <img src="Results/early_reward_50.png" width="300" height="200" />
  <img src="Results/early_reward_100.png" width="300" height="200" />
</p>

<hr>



